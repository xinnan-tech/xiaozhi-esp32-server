import logging
import json
import asyncio
import time
import traceback

import numpy as np
import opuslib
import torch
import torchaudio

from core.utils.util import remove_punctuation_and_length, get_string_no_punctuation_or_emoji

logger = logging.getLogger(__name__)


def resample_audio(audio, original_sample_rate, target_sample_rate=16000):
    """ ä½¿ç”¨ torchaudio å¯¹éŸ³é¢‘è¿›è¡Œé‡é‡‡æ · """
    if original_sample_rate != target_sample_rate:
        resampler = torchaudio.transforms.Resample(orig_freq=original_sample_rate, new_freq=target_sample_rate)
        audio = resampler(audio)
    return audio


def opus_to_pcm(opus_data, original_sample_rate):
    """ å°† Opus éŸ³é¢‘è§£ç ä¸º PCM """
    decoder = opuslib.Decoder(original_sample_rate, 1)
    pcm_data = decoder.decode(opus_data, 1440)  # 24000 é‡‡æ ·ç‡æ¯å¸§1440ä¸ªæ ·æœ¬ï¼ˆ60msï¼‰
    return pcm_data


def pcm_to_opus(pcm_data, sample_rate):
    """ å°† PCM æ•°æ®ç¼–ç ä¸º Opus æ ¼å¼ """
    encoder = opuslib.Encoder(sample_rate, 1, opuslib.APPLICATION_AUDIO)
    opus_data = encoder.encode(pcm_data,960)
    return opus_data


def convert_opus_24k_to_16k(opus_data_24k):
    # è§£ç  Opus 24k æ•°æ®ä¸º PCM
    pcm_data = opus_to_pcm(opus_data_24k, 24000)

    # å°† PCM æ•°æ®é‡é‡‡æ ·åˆ° 16k
    waveform = torch.from_numpy(np.frombuffer(pcm_data, dtype=np.int16).astype(np.float32) / 32768.0)  # è½¬æ¢ä¸º float32 å¼ é‡
    resampled_waveform = resample_audio(waveform, 24000, 16000)

    # è½¬æ¢å› int16 æ ¼å¼çš„ PCM æ•°æ®
    resampled_pcm_data = (resampled_waveform.numpy() * 32768.0).astype(np.int16)

    # é‡æ–°ç¼–ç ä¸º Opus æ ¼å¼
    opus_data_16k = pcm_to_opus(resampled_pcm_data.tobytes(), 16000)
    return opus_data_16k

async def handleAudioMessage(conn, audio):
    # 24kè½¬16k
    audio = convert_opus_24k_to_16k(audio)
    if not conn.asr_server_receive:
        logger.debug(f"å‰æœŸæ•°æ®å¤„ç†ä¸­ï¼Œæš‚åœæ¥æ”¶")
        return
    if conn.client_listen_mode == "auto":
        have_voice = conn.vad.is_vad(conn, audio)
    else:
        have_voice = conn.client_have_voice

    # å¦‚æœæœ¬æ¬¡æ²¡æœ‰å£°éŸ³ï¼Œæœ¬æ®µä¹Ÿæ²¡å£°éŸ³ï¼Œå°±æŠŠå£°éŸ³ä¸¢å¼ƒäº†
    if have_voice == False and conn.client_have_voice == False:
        conn.asr_audio.clear()
        return
    conn.asr_audio.append(audio)
    # å¦‚æœæœ¬æ®µæœ‰å£°éŸ³ï¼Œä¸”å·²ç»åœæ­¢äº†
    if conn.client_voice_stop:
        conn.client_abort = False
        conn.asr_server_receive = False
        text, file_path = conn.asr.speech_to_text(conn.asr_audio, conn.session_id)
        logger.info(f"è¯†åˆ«æ–‡æœ¬: {text}")
        text_len = remove_punctuation_and_length(text)
        if text_len > 0:
            await startToChat(conn, text)
        else:
            conn.asr_server_receive = True
        conn.asr_audio.clear()
        conn.reset_vad_states()

async def startToChat(conn, text):
    stt_text = get_string_no_punctuation_or_emoji(text)
    await conn.websocket.send(json.dumps({
        "type": "stt",
        "text": stt_text,
        "session_id": conn.session_id}
    ))
    await conn.websocket.send(
        json.dumps({
            "type": "llm",
            "text": "ğŸ˜Š",
            "emotion": "happy",
            "session_id": conn.session_id}
        ))
    conn.executor.submit(conn.chat, text)

async def sendAudioMessageStream(conn, audios_queue, duration, text):
    base_delay = conn.tts_duration

    if text == conn.tts_first_text:
        conn.tts_start_speak_time = time.time()
        await conn.websocket.send(json.dumps({
            "type": "tts",
            "state": "start",
            "session_id": conn.session_id
        }))

    # è°ƒåº¦æ–‡å­—æ˜¾ç¤ºä»»åŠ¡
    text_task = asyncio.create_task(
        schedule_with_interrupt(
            base_delay - 0.5,
            send_sentence_start(conn, text)
        )
    )
    conn.scheduled_tasks.append(text_task)

    conn.tts_duration = 0

    # å‘é€éŸ³é¢‘æ•°æ® -è·å–é˜Ÿåˆ—çš„æ•°æ®å‘é€
    start_time = time.time()
    check_index = 0
    while True:
        try:
            start_get_queue = time.time()
            # å°è¯•è·å–æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰æ•°æ®ï¼Œåˆ™ç­‰å¾…ä¸€å°æ®µæ—¶é—´å†è¯•
            audio_data_chunke = None
            try:
                audio_data_chunke = audios_queue.get(timeout=5)  # è®¾ç½®è¶…æ—¶ä¸º1ç§’
            except Exception as e:
                # å¦‚æœè¶…æ—¶ï¼Œç»§ç»­ç­‰å¾…
                print(f"è·å–é˜Ÿåˆ—è¶…æ—¶ï½{e}")


            audio_data_chunke_data = audio_data_chunke.get('data') if audio_data_chunke else None

            if audio_data_chunke:
                start_time = time.time()
            #æ£€æŸ¥æ˜¯å¦è¶…è¿‡ 5 ç§’æ²¡æœ‰æ•°æ®
            if time.time() - start_time > 5:
                print("è¶…è¿‡5ç§’æ²¡æœ‰æ•°æ®ï¼Œé€€å‡ºã€‚")
                break

            if audio_data_chunke and audio_data_chunke.get("end", True):
                break

            if audio_data_chunke_data:
                queue_duration = time.time() - start_get_queue
                last_duration = conn.tts_duration - queue_duration
                if last_duration <= 0 :
                    last_duration = 0
                opus_datas, duration = conn.tts.wav_to_opus_data_audio(audio_data_chunke_data)
                conn.tts_duration = duration + last_duration + 0.5
                for opus_packet in opus_datas:
                    await conn.websocket.send(opus_packet)
                print(f"å·²è·å–éŸ³é¢‘æ•°æ®ï¼Œé•¿åº¦ä¸º {len(audio_data_chunke_data)}ï¼Œæ€»é•¿åº¦ä¸º {len(audio_data_chunke_data)}")
                start_time = time.time()  # æ›´æ–°è·å–æ•°æ®çš„æ—¶é—´
        except Exception as e:
            print(f"å‘ç”Ÿé”™è¯¯: {e}")
            traceback.print_exc()  # æ‰“å°é”™è¯¯å †æ ˆ

    if conn.llm_finish_task and text == conn.tts_last_text:
        stop_duration = conn.tts_duration + 0.5
        stop_task = asyncio.create_task(
            schedule_with_interrupt(stop_duration, send_tts_stop(conn, text))
        )
        conn.scheduled_tasks.append(stop_task)

async def sendAudioMessage(conn, audios, duration, text):
    base_delay = conn.tts_duration

    if text == conn.tts_first_text:
        conn.tts_start_speak_time = time.time()
        await conn.websocket.send(json.dumps({
            "type": "tts",
            "state": "start",
            "session_id": conn.session_id
        }))

    # è°ƒåº¦æ–‡å­—æ˜¾ç¤ºä»»åŠ¡
    text_task = asyncio.create_task(
        schedule_with_interrupt(
            base_delay - 0.5,
            send_sentence_start(conn, text)
        )
    )
    conn.scheduled_tasks.append(text_task)

    conn.tts_duration = conn.tts_duration + duration

    # å‘é€éŸ³é¢‘æ•°æ®
    for opus_packet in audios:
        await conn.websocket.send(opus_packet)

    if conn.llm_finish_task and text == conn.tts_last_text:
        stop_duration = conn.tts_duration - (time.time() - conn.tts_start_speak_time)
        stop_task = asyncio.create_task(
            schedule_with_interrupt(stop_duration, send_tts_stop(conn, text))
        )
        conn.scheduled_tasks.append(stop_task)


async def send_sentence_start(conn, text):
    await conn.websocket.send(json.dumps({
        "type": "tts",
        "state": "sentence_start",
        "text": text,
        "session_id": conn.session_id
    }))


async def send_tts_stop(conn, text):
    conn.clearSpeakStatus()
    await conn.websocket.send(json.dumps({
        "type": "tts",
        "state": "sentence_end",
        "text": text,
        "session_id": conn.session_id
    }))
    await conn.websocket.send(json.dumps({
        "type": "tts",
        "state": "stop",
        "session_id": conn.session_id
    }))


async def schedule_with_interrupt(delay, coro):
    """å¯ä¸­æ–­çš„å»¶è¿Ÿè°ƒåº¦"""
    try:
        await asyncio.sleep(delay)
        await coro
    except asyncio.CancelledError:
        pass
