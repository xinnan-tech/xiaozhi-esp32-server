import os
import time
import torch
import pyaudio
import numpy as np
from collections import deque
from scipy.io import wavfile
from scipy.spatial.distance import cosine
from speechbrain.pretrained import SpeakerRecognition

from core.providers.speaker.base import SpeakerProviderBase
from typing import Optional, Tuple, List

import wave
import uuid

from config.logger import setup_logging

TAG = __name__
logger = setup_logging()

# éŸ³é¢‘å‚æ•°
SAMPLE_RATE = 16000
CHUNK = 1024
CHANNELS = 1
FORMAT = pyaudio.paInt16
BUFFER_SECONDS = 2
THRESHOLD = 0.35
ENROLL_FILE = "enrolled_voice.wav"



class SpeechBrainProvider(SpeakerProviderBase):
    def __init__(self, config: dict, delete_audio_file: bool):
        super().__init__()
        self.delete_audio_file = delete_audio_file

        # åˆå§‹åŒ–æ¨¡å‹
        print("ğŸ” æ­£åœ¨åŠ è½½è¯´è¯äººè¯†åˆ«æ¨¡å‹...")
        self.model = SpeakerRecognition.from_hparams(source="speechbrain/spkrec-ecapa-voxceleb")
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    def load_audio_embedding(self,filepath):
        wav_tensor = self.model.load_audio(filepath).unsqueeze(0)
        embed = self.model.encode_batch(wav_tensor).squeeze().detach().cpu().numpy()
        return embed

    def verify_from_array(self,audio_array: np.ndarray):
        global owner_embed
        print("ğŸ” æ­£åœ¨åŠ è½½owner_embed...")
        owner_embed = self.load_audio_embedding(ENROLL_FILE)
        if audio_array.dtype != np.float32:
            audio_array = audio_array.astype(np.float32)

        audio_tensor = torch.from_numpy(audio_array).unsqueeze(0)
        embed = self.model.encode_batch(audio_tensor).squeeze().detach().cpu().numpy()
        score = 1 - cosine(owner_embed, embed)
        return score

    def save_audio_to_file(self, pcm_data: List[bytes], session_id: str) -> str:
        """PCMæ•°æ®ä¿å­˜ä¸ºWAVæ–‡ä»¶"""
        module_name = __name__.split(".")[-1]
        file_name = f"speaker_{module_name}_{session_id}_{uuid.uuid4()}.wav"
        file_path = os.path.join(self.output_dir, file_name)

        with wave.open(file_path, "wb") as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # 2 bytes = 16-bit
            wf.setframerate(16000)
            wf.writeframes(b"".join(pcm_data))

        return file_path

    def verify_voice(
        self, file_path: str,audio_data: List[bytes], session_id: str
    ) -> Tuple[Optional[bool], Optional[float]]:
        """éªŒè¯è¯´è¯äººå¤„ç†é€»è¾‘"""

        # ä½¿ç”¨ SpeechBrain æ¨¡å‹å¯¹æ¯”
        score, prediction = self.model.verify_files(ENROLL_FILE, file_path)
        # os.remove(temp_file)

        print(f"[è¯†åˆ«ç»“æœ] ç›¸ä¼¼åº¦åˆ†æ•°ï¼š{score.item():.4f}")
        if prediction:
            print("âœ… è¯´è¯äººèº«ä»½é€šè¿‡ï¼ˆä¸æ³¨å†Œå£°éŸ³ä¸€è‡´ï¼‰")
            return prediction,score
        else:
            print("âŒ è¯´è¯äººèº«ä»½ä¸ä¸€è‡´")
            return False,-1.0



