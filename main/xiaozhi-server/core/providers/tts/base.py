import os
import re
import time
import uuid
import queue
import asyncio
import threading
import traceback
from typing import Optional
from concurrent.futures import ThreadPoolExecutor
from core.utils import p3
from datetime import datetime
from core.utils import textUtils
from typing import Callable, Any
from abc import ABC, abstractmethod
from config.logger import setup_logging
from core.utils.tts import MarkdownCleaner
from core.utils.output_counter import add_device_output
from core.handle.reportHandle import enqueue_tts_report
from core.handle.sendAudioHandle import sendAudioMessage
from core.utils.util import audio_bytes_to_data_stream, audio_to_data_stream
from core.providers.tts.dto.dto import (
    TTSMessageDTO,
    SentenceType,
    ContentType,
    InterfaceType,
    TTSAudioDTO,
    MessageTag,
)

TAG = __name__
logger = setup_logging()

# TTS ç”Ÿæˆçº¿ç¨‹æ± ï¼ˆå…¨å±€å…±äº«ï¼Œé¿å…é¢‘ç¹åˆ›å»ºï¼‰
_tts_executor = ThreadPoolExecutor(max_workers=3, thread_name_prefix="tts_gen_")


class TTSProviderBase(ABC):
    def __init__(self, config, delete_audio_file):
        self.interface_type = InterfaceType.NON_STREAM
        self.conn = None
        self.delete_audio_file = delete_audio_file
        self.audio_file_type = "wav"
        self.output_file = config.get("output_dir", "tmp/")
        self.tts_text_queue = queue.Queue[TTSMessageDTO]()
        # TODO: for long-term, we need to use TTSAudioDTO instead of tuple[SentenceType, Optional[bytes], Optional[str]]
        self.tts_audio_queue = queue.Queue[TTSAudioDTO | tuple[SentenceType, Optional[bytes], Optional[str]]]()
        self.tts_audio_first_sentence = True
        self.before_stop_play_files = []
        self._message_tag = MessageTag.NORMAL

        self.tts_text_buff = []
        self.punctuations = (
            "ã€‚",
            "ï¼Ÿ",
            "?",
            "ï¼",
            "!",
            "ï¼›",
            ";",
            "ï¼š",
            ".",
            "!"
        )
        self.first_sentence_punctuations = (
            "ï¼Œ",  # å¯ç”¨é€—å·ï¼Œè®©é¦–æ®µæ›´å¿«æ’­æ”¾
            "~",
            "ã€",
            ",",  # å¯ç”¨è‹±æ–‡é€—å·
            "ã€‚",
            "ï¼Ÿ",
            "?",
            "ï¼",
            "!",
            "ï¼›",
            ";",
            "ï¼š",
        )
        self.tts_stop_request = False
        self.processed_chars = 0
        self.is_first_sentence = True

    def generate_filename(self, extension=".wav"):
        return os.path.join(
            self.output_file,
            f"tts-{datetime.now().date()}@{uuid.uuid4().hex}{extension}",
        )

    def handle_opus(self, opus_data: bytes):
        logger.bind(tag=TAG).debug(f"æ¨é€æ•°æ®åˆ°é˜Ÿåˆ—é‡Œé¢å¸§æ•°ï½ï½ {len(opus_data)}")
        self.tts_audio_queue.put((SentenceType.MIDDLE, opus_data, None))

    def handle_audio_file(self, file_audio: bytes, text):
        self.before_stop_play_files.append((file_audio, text))

    def to_tts_stream(self, text, opus_handler: Callable[[bytes], None] = None) -> None:
        text = MarkdownCleaner.clean_markdown(text)
        max_repeat_time = 5
        if self.delete_audio_file:
            # éœ€è¦åˆ é™¤æ–‡ä»¶çš„ç›´æ¥è½¬ä¸ºéŸ³é¢‘æ•°æ®
            while max_repeat_time > 0:
                try:
                    audio_bytes = asyncio.run(self.text_to_speak(text, None))
                    if audio_bytes:
                        self.tts_audio_queue.put((SentenceType.FIRST, None, text))
                        audio_bytes_to_data_stream(
                            audio_bytes,
                            file_type=self.audio_file_type,
                            is_opus=True,
                            callback=opus_handler,
                        )
                        break
                    else:
                        max_repeat_time -= 1
                except Exception as e:
                    logger.bind(tag=TAG).warning(
                        f"è¯­éŸ³ç”Ÿæˆå¤±è´¥{5 - max_repeat_time + 1}æ¬¡: {text}ï¼Œé”™è¯¯: {e}"
                    )
                    max_repeat_time -= 1
            if max_repeat_time > 0:
                logger.bind(tag=TAG).info(
                    f"è¯­éŸ³ç”ŸæˆæˆåŠŸ: {text}ï¼Œé‡è¯•{5 - max_repeat_time}æ¬¡"
                )
            else:
                logger.bind(tag=TAG).error(
                    f"è¯­éŸ³ç”Ÿæˆå¤±è´¥: {text}ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æœåŠ¡æ˜¯å¦æ­£å¸¸"
                )
            return None
        else:
            tmp_file = self.generate_filename()
            try:
                while not os.path.exists(tmp_file) and max_repeat_time > 0:
                    try:
                        asyncio.run(self.text_to_speak(text, tmp_file))
                    except Exception as e:
                        logger.bind(tag=TAG).warning(
                            f"è¯­éŸ³ç”Ÿæˆå¤±è´¥{5 - max_repeat_time + 1}æ¬¡: {text}ï¼Œé”™è¯¯: {e}"
                        )
                        # æœªæ‰§è¡ŒæˆåŠŸï¼Œåˆ é™¤æ–‡ä»¶
                        if os.path.exists(tmp_file):
                            os.remove(tmp_file)
                        max_repeat_time -= 1

                if max_repeat_time > 0:
                    logger.bind(tag=TAG).info(
                        f"è¯­éŸ³ç”ŸæˆæˆåŠŸ: {text}:{tmp_file}ï¼Œé‡è¯•{5 - max_repeat_time}æ¬¡"
                    )
                else:
                    logger.bind(tag=TAG).error(
                        f"è¯­éŸ³ç”Ÿæˆå¤±è´¥: {text}ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æœåŠ¡æ˜¯å¦æ­£å¸¸"
                    )
                    self.tts_audio_queue.put((SentenceType.FIRST, None, text))
                self._process_audio_file_stream(tmp_file, callback=opus_handler)
            except Exception as e:
                logger.bind(tag=TAG).error(f"Failed to generate TTS file: {e}")
                return None
    
    def to_tts(self, text):
        text = MarkdownCleaner.clean_markdown(text)
        max_repeat_time = 5
        if self.delete_audio_file:
            # éœ€è¦åˆ é™¤æ–‡ä»¶çš„ç›´æ¥è½¬ä¸ºéŸ³é¢‘æ•°æ®
            while max_repeat_time > 0:
                try:
                    audio_bytes = asyncio.run(self.text_to_speak(text, None))
                    if audio_bytes:
                        audio_datas = []
                        audio_bytes_to_data_stream(
                            audio_bytes,
                            file_type=self.audio_file_type,
                            is_opus=True,
                            callback=lambda data: audio_datas.append(data)
                        )
                        return audio_datas
                    else:
                        max_repeat_time -= 1
                except Exception as e:
                    logger.bind(tag=TAG).warning(
                        f"è¯­éŸ³ç”Ÿæˆå¤±è´¥{5 - max_repeat_time + 1}æ¬¡: {text}ï¼Œé”™è¯¯: {e}"
                    )
                    max_repeat_time -= 1
            if max_repeat_time > 0:
                logger.bind(tag=TAG).info(
                    f"è¯­éŸ³ç”ŸæˆæˆåŠŸ: {text}ï¼Œé‡è¯•{5 - max_repeat_time}æ¬¡"
                )
            else:
                logger.bind(tag=TAG).error(
                    f"è¯­éŸ³ç”Ÿæˆå¤±è´¥: {text}ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æœåŠ¡æ˜¯å¦æ­£å¸¸"
                )
            return None
        else:
            tmp_file = self.generate_filename()
            try:
                while not os.path.exists(tmp_file) and max_repeat_time > 0:
                    try:
                        asyncio.run(self.text_to_speak(text, tmp_file))
                    except Exception as e:
                        logger.bind(tag=TAG).warning(
                            f"è¯­éŸ³ç”Ÿæˆå¤±è´¥{5 - max_repeat_time + 1}æ¬¡: {text}ï¼Œé”™è¯¯: {e}"
                        )
                        # æœªæ‰§è¡ŒæˆåŠŸï¼Œåˆ é™¤æ–‡ä»¶
                        if os.path.exists(tmp_file):
                            os.remove(tmp_file)
                        max_repeat_time -= 1

                if max_repeat_time > 0:
                    logger.bind(tag=TAG).info(
                        f"è¯­éŸ³ç”ŸæˆæˆåŠŸ: {text}:{tmp_file}ï¼Œé‡è¯•{5 - max_repeat_time}æ¬¡"
                    )
                else:
                    logger.bind(tag=TAG).error(
                        f"è¯­éŸ³ç”Ÿæˆå¤±è´¥: {text}ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æœåŠ¡æ˜¯å¦æ­£å¸¸"
                    )

                return tmp_file
            except Exception as e:
                logger.bind(tag=TAG).error(f"Failed to generate TTS file: {e}")
                return None

    @abstractmethod
    async def text_to_speak(self, text, output_file):
        pass

    def audio_to_pcm_data_stream(
        self, audio_file_path, callback: Callable[[Any], Any] = None
    ):
        """éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºPCMç¼–ç """
        return audio_to_data_stream(audio_file_path, is_opus=False, callback=callback)

    def audio_to_opus_data_stream(
        self, audio_file_path, callback: Callable[[Any], Any] = None
    ):
        """éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºOpusç¼–ç """
        return audio_to_data_stream(audio_file_path, is_opus=True, callback=callback)

    def tts_one_sentence(
        self,
        conn,
        content_type,
        content_detail=None,
        content_file=None,
        sentence_id=None,
    ):
        """å‘é€ä¸€å¥è¯"""
        if not sentence_id:
            if conn.sentence_id:
                sentence_id = conn.sentence_id
            else:
                sentence_id = str(uuid.uuid4().hex)
                conn.sentence_id = sentence_id
        # å¯¹äºå•å¥çš„æ–‡æœ¬ï¼Œè¿›è¡Œåˆ†æ®µå¤„ç†
        segments = re.split(r"([ã€‚ï¼ï¼Ÿ!?ï¼›;\n])", content_detail)
        for seg in segments:
            self.tts_text_queue.put(
                TTSMessageDTO(
                    sentence_id=sentence_id,
                    sentence_type=SentenceType.MIDDLE,
                    content_type=content_type,
                    content_detail=seg,
                    content_file=content_file,
                )
            )

    async def open_audio_channels(self, conn):
        self.conn = conn
        # tts æ¶ˆåŒ–çº¿ç¨‹
        self.tts_priority_thread = threading.Thread(
            target=self.tts_text_priority_thread, daemon=True
        )
        self.tts_priority_thread.start()

        # éŸ³é¢‘æ’­æ”¾ æ¶ˆåŒ–çº¿ç¨‹
        self.audio_play_priority_thread = threading.Thread(
            target=self._audio_play_priority_thread, daemon=True
        )
        self.audio_play_priority_thread.start()

    # è¿™é‡Œé»˜è®¤æ˜¯éæµå¼çš„å¤„ç†æ–¹å¼
    # æµå¼å¤„ç†æ–¹å¼è¯·åœ¨å­ç±»ä¸­é‡å†™
    def tts_text_priority_thread(self):
        while not self.conn.stop_event.is_set():
            try:
                message = self.tts_text_queue.get(timeout=1)
                if message.sentence_type == SentenceType.FIRST:
                    self.conn.client_abort = False
                if self.conn.client_abort:
                    logger.bind(tag=TAG).info("æ”¶åˆ°æ‰“æ–­ä¿¡æ¯ï¼Œç»ˆæ­¢TTSæ–‡æœ¬å¤„ç†çº¿ç¨‹")
                    continue
                if message.sentence_type == SentenceType.FIRST:
                    # åˆå§‹åŒ–å‚æ•°
                    self.tts_stop_request = False
                    self.processed_chars = 0
                    self.tts_text_buff = []
                    self.is_first_sentence = True
                    self.tts_audio_first_sentence = True
                    self.conn._latency_tts_first_text_time = None  # Reset TTS input time
                elif ContentType.TEXT == message.content_type:
                    self.tts_text_buff.append(message.content_detail)
                    segment_text = self._get_segment_text()
                    if segment_text:
                        # Record TTS first text input time (for latency tracking)
                        if not hasattr(self.conn, '_latency_tts_first_text_time') or self.conn._latency_tts_first_text_time is None:
                            import time
                            self.conn._latency_tts_first_text_time = time.time() * 1000
                            logger.bind(tag=TAG).debug("ğŸ“ [å»¶è¿Ÿè¿½è¸ª] TTSé¦–æ¬¡æ¥æ”¶æ–‡æœ¬")
                        self.to_tts_stream(segment_text, opus_handler=self.handle_opus)
                elif ContentType.FILE == message.content_type:
                    self._process_remaining_text_stream(opus_handler=self.handle_opus)
                    tts_file = message.content_file
                    if tts_file and os.path.exists(tts_file):
                        self._process_audio_file_stream(
                            tts_file, callback=self.handle_opus
                        )
                if message.sentence_type == SentenceType.LAST:
                    self._process_remaining_text_stream(opus_handler=self.handle_opus)
                    self.tts_audio_queue.put(
                        (message.sentence_type, [], message.content_detail)
                    )

            except queue.Empty:
                continue
            except Exception as e:
                logger.bind(tag=TAG).error(
                    f"å¤„ç†TTSæ–‡æœ¬å¤±è´¥: {str(e)}, ç±»å‹: {type(e).__name__}, å †æ ˆ: {traceback.format_exc()}"
                )
                continue

    def _audio_play_priority_thread(self):
        # éœ€è¦ä¸ŠæŠ¥çš„æ–‡æœ¬å’ŒéŸ³é¢‘åˆ—è¡¨
        enqueue_text = None
        enqueue_audio = None
        # ç”¨äºè·Ÿè¸ªä¸Šä¸€ä¸ªå‘é€ä»»åŠ¡ï¼Œç¡®ä¿é¡ºåºä½†ä¸é˜»å¡
        last_send_future = None
        
        while not self.conn.stop_event.is_set():
            text = None
            try:
                try:
                    tts_audio_message = self.tts_audio_queue.get(
                        timeout=0.1
                    )
                    if isinstance(tts_audio_message, TTSAudioDTO):
                        sentence_type = tts_audio_message.sentence_type
                        audio_datas = tts_audio_message.audio_data
                        text = tts_audio_message.text
                        message_tag = tts_audio_message.message_tag
                    elif isinstance(tts_audio_message, tuple):
                        sentence_type = tts_audio_message[0]
                        audio_datas = tts_audio_message[1]
                        text = tts_audio_message[2]
                        message_tag = MessageTag.NORMAL  # tuple format doesn't have message_tag
                    else:
                        logger.bind(tag=TAG).warning(f"Unknown tts_audio_message type: {type(tts_audio_message)}")
                        continue
                except queue.Empty:
                    if self.conn.stop_event.is_set():
                        break
                    continue

                if self.conn.client_abort:
                    logger.bind(tag=TAG).debug("æ”¶åˆ°æ‰“æ–­ä¿¡å·ï¼Œè·³è¿‡å½“å‰éŸ³é¢‘æ•°æ®")
                    enqueue_text, enqueue_audio = None, []
                    last_send_future = None
                    continue

                # æ”¶åˆ°ä¸‹ä¸€ä¸ªæ–‡æœ¬å¼€å§‹æˆ–ä¼šè¯ç»“æŸæ—¶è¿›è¡Œä¸ŠæŠ¥
                if sentence_type is not SentenceType.MIDDLE:
                    # ä¸ŠæŠ¥TTSæ•°æ®
                    if enqueue_text is not None and enqueue_audio is not None:
                        enqueue_tts_report(self.conn, enqueue_text, enqueue_audio, message_tag)
                    enqueue_audio = []
                    enqueue_text = text

                # æ”¶é›†ä¸ŠæŠ¥éŸ³é¢‘æ•°æ®
                if isinstance(audio_datas, bytes) and enqueue_audio is not None:
                    enqueue_audio.append(audio_datas)

                # ç­‰å¾…ä¸Šä¸€ä¸ªå‘é€å®Œæˆï¼ˆä¿æŒé¡ºåºï¼‰ï¼Œä½†ä½¿ç”¨çŸ­è¶…æ—¶é¿å…é•¿æ—¶é—´é˜»å¡
                if last_send_future is not None:
                    try:
                        last_send_future.result(timeout=5.0)
                    except Exception as e:
                        logger.bind(tag=TAG).warning(f"ä¸Šä¸€ä¸ªéŸ³é¢‘å‘é€è¶…æ—¶æˆ–å¤±è´¥: {e}")

                # å¼‚æ­¥å‘é€éŸ³é¢‘ï¼ˆä¸é˜»å¡ç­‰å¾…ï¼‰
                last_send_future = asyncio.run_coroutine_threadsafe(
                    sendAudioMessage(self.conn, sentence_type, audio_datas, text, message_tag),
                    self.conn.loop,
                )

                # è®°å½•è¾“å‡ºå’ŒæŠ¥å‘Š
                if self.conn.max_output_size > 0 and text:
                    add_device_output(self.conn.headers.get("device-id"), len(text))

            except Exception as e:
                logger.bind(tag=TAG).error(f"audio_play_priority_thread: {text} {e}")

    async def start_session(self, session_id):
        pass

    async def finish_session(self, session_id):
        pass

    async def close(self):
        """èµ„æºæ¸…ç†æ–¹æ³•"""
        if hasattr(self, "ws") and self.ws:
            await self.ws.close()

    def _get_segment_text(self):
        # åˆå¹¶å½“å‰å…¨éƒ¨æ–‡æœ¬å¹¶å¤„ç†æœªåˆ†å‰²éƒ¨åˆ†
        full_text = "".join(self.tts_text_buff)
        current_text = full_text[self.processed_chars :]  # ä»æœªå¤„ç†çš„ä½ç½®å¼€å§‹
        last_punct_pos = -1
        
        # é¦–å¥æœ€å°å­—ç¬¦æ•°ï¼ˆé¿å…é¦–å¥å¤ªçŸ­å¦‚"å¥½çš„ï¼Œ"ï¼‰
        MIN_FIRST_SEGMENT_CHARS = 8

        # æ ¹æ®æ˜¯å¦æ˜¯ç¬¬ä¸€å¥è¯é€‰æ‹©ä¸åŒçš„æ ‡ç‚¹ç¬¦å·é›†åˆ
        punctuations_to_use = (
            self.first_sentence_punctuations
            if self.is_first_sentence
            else self.punctuations
        )

        for punct in punctuations_to_use:
            pos = current_text.rfind(punct)
            if (pos != -1 and last_punct_pos == -1) or (
                pos != -1 and pos < last_punct_pos
            ):
                last_punct_pos = pos

        if last_punct_pos != -1:
            segment_text_raw = current_text[: last_punct_pos + 1]
            
            # é¦–å¥é•¿åº¦æ£€æŸ¥ï¼šå¦‚æœå¤ªçŸ­ï¼Œç­‰å¾…æ›´å¤šæ–‡æœ¬
            # if self.is_first_sentence and len(segment_text_raw) < MIN_FIRST_SEGMENT_CHARS:
            #     return None  # ç»§ç»­ç­‰å¾…æ›´å¤šæ–‡æœ¬
            
            segment_text = textUtils.get_string_no_punctuation_or_emoji(
                segment_text_raw
            )
            self.processed_chars += len(segment_text_raw)  # æ›´æ–°å·²å¤„ç†å­—ç¬¦ä½ç½®

            # å¦‚æœæ˜¯ç¬¬ä¸€å¥è¯ï¼Œåœ¨æ‰¾åˆ°ç¬¬ä¸€ä¸ªé€—å·åï¼Œå°†æ ‡å¿—è®¾ç½®ä¸ºFalse
            if self.is_first_sentence:
                self.is_first_sentence = False

            return segment_text
        elif self.tts_stop_request and current_text:
            segment_text = current_text
            self.is_first_sentence = True  # é‡ç½®æ ‡å¿—
            return segment_text
        else:
            return None

    def _process_audio_file_stream(
        self, tts_file, callback: Callable[[Any], Any]
    ) -> None:
        """å¤„ç†éŸ³é¢‘æ–‡ä»¶å¹¶è½¬æ¢ä¸ºæŒ‡å®šæ ¼å¼

        Args:
            tts_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            callback: æ–‡ä»¶å¤„ç†å‡½æ•°
        """
        if tts_file.endswith(".p3"):
            p3.decode_opus_from_file_stream(tts_file, callback=callback)
        elif self.conn.audio_format == "pcm":
            self.audio_to_pcm_data_stream(tts_file, callback=callback)
        else:
            self.audio_to_opus_data_stream(tts_file, callback=callback)

        if (
            self.delete_audio_file
            and tts_file is not None
            and os.path.exists(tts_file)
            and tts_file.startswith(self.output_file)
        ):
            os.remove(tts_file)

    def _process_before_stop_play_files(self):
        for audio_datas, text in self.before_stop_play_files:
            self.tts_audio_queue.put((SentenceType.MIDDLE, audio_datas, text))
        self.before_stop_play_files.clear()
        self.tts_audio_queue.put((SentenceType.LAST, [], None))

    def _process_remaining_text_stream(
        self, opus_handler: Callable[[bytes], None] = None
    ):
        """å¤„ç†å‰©ä½™çš„æ–‡æœ¬å¹¶ç”Ÿæˆè¯­éŸ³

        Returns:
            bool: æ˜¯å¦æˆåŠŸå¤„ç†äº†æ–‡æœ¬
        """
        full_text = "".join(self.tts_text_buff)
        remaining_text = full_text[self.processed_chars :]
        if remaining_text:
            segment_text = textUtils.get_string_no_punctuation_or_emoji(remaining_text)
            if segment_text:
                self.to_tts_stream(segment_text, opus_handler=opus_handler)
                self.processed_chars += len(full_text)
                return True
        return False
