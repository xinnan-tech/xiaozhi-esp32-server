"""
Cartesia TTS SDK å®ç°

ä½¿ç”¨å®˜æ–¹ Cartesia Python SDK å®ç°æµå¼ TTS
æ–‡æ¡£: https://docs.cartesia.ai/
"""

import asyncio
import os
import time
from typing import Optional, Callable, Dict, Any
from config.logger import setup_logging
from core.providers.tts.base import TTSProviderBase
from core.providers.tts.dto.dto import InterfaceType

try:
    import cartesia
except ImportError:
    raise ImportError(
        "Cartesia SDK not installed. Install with: pip install cartesia"
    )

TAG = __name__
logger = setup_logging()


class TTSProvider(TTSProviderBase):
    """
    Cartesia TTS SDK æä¾›å•†
    
    ç‰¹ç‚¹ï¼š
    - ä½å»¶è¿Ÿæµå¼åˆæˆ
    - æ”¯æŒå¤šç§è¯­è¨€å’Œå£°éŸ³
    - ä½¿ç”¨å®˜æ–¹ SDKï¼Œä»£ç ç®€æ´
    
    é…ç½®ç¤ºä¾‹:
        CartesiaSDK:
            type: cartesia_sdk
            api_key: your_api_key
            voice_id: your_voice_id  # æˆ– voice_embedding
            model: sonic-english
            language: en
            encoding: pcm_s16le
            sample_rate: 24000
            output_dir: tmp/
    """
    
    def __init__(self, config: dict, delete_audio_file: bool = True):
        super().__init__(config, delete_audio_file)
        
        # æ ‡è®°ä¸ºå•æµå¼æ¥å£
        self.interface_type = InterfaceType.SINGLE_STREAM
        
        # è·å– API Key
        self.api_key = config.get("api_key") or os.environ.get("CARTESIA_API_KEY")
        if not self.api_key:
            raise ValueError(
                "Cartesia API key is required. "
                "Provide via api_key in config or set CARTESIA_API_KEY environment variable"
            )
        
        # Voice é…ç½®ï¼ˆæ”¯æŒ voice_id æˆ– voice_embeddingï¼‰
        # ä¼˜å…ˆè¯»å–é¡¶å±‚ voice_idï¼Œç„¶åæ£€æŸ¥åµŒå¥—çš„ voice.id å’Œ voice.embedding
        self.voice_id = config.get("voice_id", "")
        self.voice_embedding = None
        
        if not self.voice_id:
            voice_config = config.get("voice", {})
            if isinstance(voice_config, dict):
                self.voice_id = voice_config.get("id", "")
                self.voice_embedding = voice_config.get("embedding")
            elif voice_config:  # å¦‚æœ voice æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½œä¸º voice_id
                self.voice_id = voice_config
        
        # æ¨¡å‹å’Œè¯­è¨€é…ç½®
        self.model = config.get("model", "sonic-english")
        self.language = config.get("language", "en")
        
        # éŸ³é¢‘é…ç½®
        self.encoding = config.get("encoding", "pcm_s16le")
        self.sample_rate = config.get("sample_rate", 24000)
        
        # éªŒè¯è‡³å°‘æœ‰ä¸€ä¸ª voice é…ç½®
        if not self.voice_id and not self.voice_embedding:
            raise ValueError(
                "Voice configuration is required. "
                "Provide either voice_id or voice.embedding in config"
            )
        
        # åˆå§‹åŒ– SDK å®¢æˆ·ç«¯
        self.client = cartesia.Cartesia(api_key=self.api_key)
        self._ws_client = None
        
        logger.bind(tag=TAG).info(
            f"Cartesia SDK initialized: model={self.model}, "
            f"voice_id={self.voice_id[:8]+'...' if self.voice_id else 'embedding'}, "
            f"language={self.language}, "
            f"encoding={self.encoding}, sample_rate={self.sample_rate}"
        )
    
    async def _get_ws_client(self):
        """è·å–æˆ–åˆ›å»º WebSocket å®¢æˆ·ç«¯ï¼ˆå¤ç”¨è¿æ¥ï¼‰"""
        if self._ws_client is None:
            self._ws_client = self.client.tts.websocket()
        return self._ws_client
    
    def _prepare_voice_param(self) -> Dict[str, Any]:
        """å‡†å¤‡ voice å‚æ•°ï¼ˆé¿å…é‡å¤ä»£ç ï¼‰"""
        if self.voice_id:
            return {
                "mode": "id",
                "id": self.voice_id
            }
        elif self.voice_embedding:
            return {
                "mode": "embedding",
                "embedding": self.voice_embedding
            }
        else:
            raise ValueError("Neither voice_id nor voice_embedding is configured")
    
    async def text_to_speak(self, text: str, output_file: Optional[str] = None) -> Optional[bytes]:
        """
        éæµå¼æ–¹æ³•ï¼šå°†å®Œæ•´æ–‡æœ¬è½¬æ¢ä¸ºéŸ³é¢‘
        
        æ³¨æ„ï¼šCartesia ä¸»è¦è®¾è®¡ä¸ºæµå¼ä½¿ç”¨ï¼Œæ­¤æ–¹æ³•ä¼šç­‰å¾…å®Œæ•´éŸ³é¢‘ç”Ÿæˆ
        å»ºè®®ä½¿ç”¨ to_tts_stream() æ–¹æ³•ä»¥è·å¾—æ›´ä½çš„å»¶è¿Ÿ
        """
        try:
            ws = await self._get_ws_client()
            
            audio_chunks = []
            voice = self._prepare_voice_param()
            
            # å‘é€æµå¼è¯·æ±‚
            for output in ws.send(
                model_id=self.model,
                transcript=text,
                voice=voice,
                stream=True,
                output_format={
                    "container": "raw",
                    "encoding": self.encoding,
                    "sample_rate": self.sample_rate
                }
            ):
                # Cartesia SDK è¿”å› WebSocketTtsOutput å¯¹è±¡
                # ä» output.audio è·å–éŸ³é¢‘æ•°æ®
                if output and hasattr(output, 'audio') and output.audio:
                    audio_chunks.append(output.audio)
            
            # åˆå¹¶æ‰€æœ‰éŸ³é¢‘å—
            audio_data = b''.join(audio_chunks)
            
            # ä¿å­˜åˆ°æ–‡ä»¶æˆ–è¿”å›
            if output_file:
                with open(output_file, 'wb') as f:
                    f.write(audio_data)
                logger.bind(tag=TAG).info(f"Audio saved to {output_file}, size: {len(audio_data)} bytes")
                return None
            else:
                return audio_data
                
        except Exception as e:
            logger.bind(tag=TAG).error(f"Cartesia TTS failed: {e}", exc_info=True)
            raise
    
    def to_tts_stream(self, text: str, opus_handler: Optional[Callable] = None):
        """
        æµå¼ç”ŸæˆéŸ³é¢‘ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰
        
        æ³¨æ„ï¼šæµè§ˆå™¨ç«¯ä½¿ç”¨ Web Audio API æ’­æ”¾ï¼Œç›´æ¥å‘é€ PCM æ•°æ®
        ESP32 ç­‰åµŒå…¥å¼è®¾å¤‡ä½¿ç”¨ Opusï¼Œéœ€è¦ç¼–ç 
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            opus_handler: éŸ³é¢‘æ•°æ®å›è°ƒå‡½æ•° (æ¥æ”¶ bytes)
        """
        try:
            from core.providers.tts.dto.dto import SentenceType
            
            start_time = time.time()
            text_preview = text[:30] + "..." if len(text) > 30 else text
            logger.bind(tag=TAG).info(f"ğŸ™ï¸ TTSå¼€å§‹: [{text_preview}]")
            
            # å‘é€å¥å­å¼€å§‹æ ‡è®°
            self.tts_audio_queue.put((SentenceType.FIRST, None, text))
            
            # åœ¨å¼‚æ­¥äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                # è¿è¡Œå¼‚æ­¥åˆæˆ
                chunk_count = loop.run_until_complete(
                    self._stream_synthesis(text, opus_handler, start_time)
                )
            finally:
                loop.close()
            
            # å‘é€å¥å­ç»“æŸæ ‡è®°
            self.tts_audio_queue.put((SentenceType.LAST, None, text))
            
            end_time = time.time()
            total_time = (end_time - start_time) * 1000
            logger.bind(tag=TAG).info(
                f"âœ… TTSå®Œæˆ: {chunk_count}å—, è€—æ—¶ {total_time:.0f}ms"
            )
                
        except Exception as e:
            logger.bind(tag=TAG).error(f"TTS åˆæˆå¤±è´¥: {e}", exc_info=True)
            raise
    
    async def _stream_synthesis(self, text: str, opus_handler: Optional[Callable], start_time: float) -> int:
        """
        å¼‚æ­¥æµå¼åˆæˆå®ç°
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            opus_handler: éŸ³é¢‘æ•°æ®å›è°ƒå‡½æ•°
            start_time: å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—é¦–åŒ…å»¶è¿Ÿï¼‰
            
        Returns:
            ç”Ÿæˆçš„éŸ³é¢‘å—æ•°é‡
        """
        try:
            ws = await self._get_ws_client()
            voice = self._prepare_voice_param()
            
            first_chunk_time = None
            chunk_count = 0
            
            # å‘é€æµå¼è¯·æ±‚å¹¶å¤„ç†å“åº”
            for output in ws.send(
                model_id=self.model,
                transcript=text,
                voice=voice,
                stream=True,
                output_format={
                    "container": "raw",
                    "encoding": self.encoding,
                    "sample_rate": self.sample_rate
                },
                language=self.language
            ):
                # Cartesia SDK è¿”å› WebSocketTtsOutput å¯¹è±¡
                # éœ€è¦ä» output.audio è·å–å®é™…çš„éŸ³é¢‘æ•°æ®
                if output and hasattr(output, 'audio'):
                    audio_data = output.audio
                    
                    if audio_data:
                        if first_chunk_time is None:
                            first_chunk_time = time.time()
                            ttfb = (first_chunk_time - start_time) * 1000
                            logger.bind(tag=TAG).info(f"âš¡ é¦–åŒ…å»¶è¿Ÿ: {ttfb:.0f}ms")
                        
                        # å‘é€éŸ³é¢‘æ•°æ®ï¼ˆbytesï¼‰
                        if opus_handler:
                            opus_handler(audio_data)
                            chunk_count += 1
            
            return chunk_count
            
        except Exception as e:
            logger.bind(tag=TAG).error(f"Stream synthesis error: {e}", exc_info=True)
            raise
    
    async def close(self):
        """å…³é—­ WebSocket è¿æ¥ï¼ˆCartesia SDK ä¼šè‡ªåŠ¨ç®¡ç†ï¼‰"""
        self._ws_client = None

