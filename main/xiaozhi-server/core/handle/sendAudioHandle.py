import json
import time
import asyncio
from core.utils import textUtils
from core.utils.util import audio_to_data
from core.providers.tts.dto.dto import (
    SentenceType,
    MessageTag,
)
from core.utils.textUtils import strip_emotion_tags
from core.utils.opus import pack_opus_with_header
from config.logger import setup_logging

TAG = __name__
logger = setup_logging()

async def sendAudioMessage(conn, sentenceType, audios, text, message_tag=MessageTag.NORMAL):
    if conn.tts.tts_audio_first_sentence:
        conn.tts.tts_audio_first_sentence = False
        await send_tts_message(conn, "start", None, message_tag)
        
        # è®°å½•é¦–å¥ TTS æ’­æ”¾æ—¶é—´ï¼ˆç«¯åˆ°ç«¯å»¶è¿Ÿçš„ç»ˆç‚¹ï¼‰
        first_audio_time = time.time() * 1000
        
        # è®¡ç®— TTS é¦–åŒ…å»¶è¿Ÿï¼ˆè¾“å…¥åˆ°è¾“å‡ºï¼‰
        tts_first_package_delay = 0
        if hasattr(conn, '_latency_tts_first_text_time') and conn._latency_tts_first_text_time:
            tts_first_package_delay = first_audio_time - conn._latency_tts_first_text_time
        
        # è®¡ç®—ç«¯åˆ°ç«¯å»¶è¿Ÿ
        e2e_total_delay = 0
        if hasattr(conn, '_latency_voice_end_time'):
            e2e_total_delay = first_audio_time - conn._latency_voice_end_time
        
        conn.logger.bind(tag=TAG).info(
            f"ğŸ”Š [å»¶è¿Ÿè¿½è¸ª] é¦–å¥TTSå¼€å§‹æ’­æ”¾ | "
            f"TTSé¦–åŒ…å»¶è¿Ÿ: {tts_first_package_delay:.0f}ms | "
            f"â±ï¸  ç«¯åˆ°ç«¯æ€»å»¶è¿Ÿ: {e2e_total_delay:.0f}ms (ç”¨æˆ·è¯´å®Œâ†’é¦–å¥æ’­æ”¾) | "
            f"æ–‡æœ¬: {text if text else '(æ— æ–‡æœ¬)'}"
        )

    if sentenceType == SentenceType.FIRST:
        await send_tts_message(conn, "sentence_start", text, message_tag)

    await sendAudio(conn, audios, message_tag=message_tag)
    # å‘é€å¥å­å¼€å§‹æ¶ˆæ¯
    if sentenceType is not SentenceType.MIDDLE:
        conn.logger.bind(tag=TAG).info(f"å‘é€éŸ³é¢‘æ¶ˆæ¯: {sentenceType}, {text}")

    # å‘é€ç»“æŸæ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯æœ€åä¸€ä¸ªæ–‡æœ¬ï¼‰
    # æ¡ä»¶1: llm_finish_task=True ä¸” LAST (æ­£å¸¸ç»“æŸ)
    # æ¡ä»¶2: LAST ä¸” MOCK (è¶…æ—¶è§¦å‘çš„ç»“æŸ)
    if conn.llm_finish_task and sentenceType == SentenceType.LAST:
        await send_tts_message(conn, "stop", None, message_tag)
        if message_tag == MessageTag.MOCK:
            return
        conn.client_is_speaking = False
        if conn.close_after_chat:
            await conn.close()


def calculate_timestamp_and_sequence(conn, start_time, packet_index, frame_duration=60):
    """
    è®¡ç®—éŸ³é¢‘æ•°æ®åŒ…çš„æ—¶é—´æˆ³å’Œåºåˆ—å·
    Args:
        conn: è¿æ¥å¯¹è±¡
        start_time: èµ·å§‹æ—¶é—´ï¼ˆæ€§èƒ½è®¡æ•°å™¨å€¼ï¼‰
        packet_index: æ•°æ®åŒ…ç´¢å¼•
        frame_duration: å¸§æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼ŒåŒ¹é… Opus ç¼–ç 
    Returns:
        tuple: (timestamp, sequence)
    """
    # è®¡ç®—æ—¶é—´æˆ³ï¼ˆä½¿ç”¨æ’­æ”¾ä½ç½®è®¡ç®—ï¼‰
    timestamp = int((start_time + packet_index * frame_duration / 1000) * 1000) % (
        2**32
    )

    # è®¡ç®—åºåˆ—å·
    if hasattr(conn, "audio_flow_control"):
        sequence = conn.audio_flow_control["sequence"]
    else:
        sequence = packet_index  # å¦‚æœæ²¡æœ‰æµæ§çŠ¶æ€ï¼Œç›´æ¥ä½¿ç”¨ç´¢å¼•

    return timestamp, sequence


async def _send_to_mqtt_gateway(conn, opus_packet, timestamp, sequence):
    """
    å‘é€å¸¦16å­—èŠ‚å¤´éƒ¨çš„opusæ•°æ®åŒ…ç»™mqtt_gateway
    Args:
        conn: è¿æ¥å¯¹è±¡
        opus_packet: opusæ•°æ®åŒ…
        timestamp: æ—¶é—´æˆ³
        sequence: åºåˆ—å·
    """
    # ä¸ºopusæ•°æ®åŒ…æ·»åŠ 16å­—èŠ‚å¤´éƒ¨
    header = bytearray(16)
    header[0] = 1  # type
    header[2:4] = len(opus_packet).to_bytes(2, "big")  # payload length
    header[4:8] = sequence.to_bytes(4, "big")  # sequence
    header[8:12] = timestamp.to_bytes(4, "big")  # æ—¶é—´æˆ³
    header[12:16] = len(opus_packet).to_bytes(4, "big")  # opusé•¿åº¦

    # å‘é€åŒ…å«å¤´éƒ¨çš„å®Œæ•´æ•°æ®åŒ…
    complete_packet = bytes(header) + opus_packet
    await conn.websocket.send(complete_packet)

async def _send_audio_with_header(conn, audios, message_tag=MessageTag.NORMAL):
    if audios is None or len(audios) == 0:
        return
    complete_packet = pack_opus_with_header(audios, message_tag)
    await conn.websocket.send(complete_packet)


# æ’­æ”¾éŸ³é¢‘
async def sendAudio(conn, audios, frame_duration=60, message_tag=MessageTag.NORMAL):
    """
    å‘é€å•ä¸ªopusåŒ…ï¼Œæ”¯æŒæµæ§
    Args:
        conn: è¿æ¥å¯¹è±¡
        opus_packet: å•ä¸ªopusæ•°æ®åŒ…
        pre_buffer: å¿«é€Ÿå‘é€éŸ³é¢‘
        frame_duration: å¸§æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼ŒåŒ¹é… Opus ç¼–ç 
    """
    if audios is None or len(audios) == 0:
        return

    # è·å–å‘é€å»¶è¿Ÿé…ç½®
    send_delay = conn.config.get("tts_audio_send_delay", -1) / 1000.0

    if isinstance(audios, bytes):
        if conn.client_abort:
            return

        conn.last_activity_time = time.time() * 1000

        # è·å–æˆ–åˆå§‹åŒ–æµæ§çŠ¶æ€
        if not hasattr(conn, "audio_flow_control"):
            conn.audio_flow_control = {
                "last_send_time": 0,
                "packet_count": 0,
                "start_time": time.perf_counter(),
                "sequence": 0,  # æ·»åŠ åºåˆ—å·
            }

        flow_control = conn.audio_flow_control
        current_time = time.perf_counter()
        
        # æµæ§é…ç½®
        pre_buffer_count = conn.config.get("tts_audio_pre_buffer_count", 8)  # é¢„ç¼“å†²åŒ…æ•°ï¼ˆçº¦480msï¼‰
        speed_multiplier = conn.config.get("tts_audio_speed_multiplier", 1.0)  # å‘é€é€Ÿåº¦å€ç‡
        
        if send_delay > 0:
            # ä½¿ç”¨å›ºå®šå»¶è¿Ÿ
            await asyncio.sleep(send_delay)
        elif flow_control["packet_count"] < pre_buffer_count:
            # é¢„ç¼“å†²é˜¶æ®µï¼šå¿«é€Ÿå‘é€ï¼Œä¸åšå»¶è¿Ÿ
            pass
        else:
            # æŒ‰ç•¥å¿«äºå®æ—¶çš„é€Ÿåº¦å‘é€
            packets_after_prebuffer = flow_control["packet_count"] - pre_buffer_count
            expected_time = flow_control["start_time"] + (
                packets_after_prebuffer * frame_duration / 1000 / speed_multiplier
            )
            delay = expected_time - current_time
            if delay > 0:
                await asyncio.sleep(delay)
            else:
                # çº æ­£è¯¯å·®
                flow_control["start_time"] += abs(delay)

        if conn.conn_from_mqtt_gateway:
            # è®¡ç®—æ—¶é—´æˆ³å’Œåºåˆ—å·
            timestamp, sequence = calculate_timestamp_and_sequence(
                conn,
                flow_control["start_time"],
                flow_control["packet_count"],
                frame_duration,
            )
            # è°ƒç”¨é€šç”¨å‡½æ•°å‘é€å¸¦å¤´éƒ¨çš„æ•°æ®åŒ…
            await _send_to_mqtt_gateway(conn, audios, timestamp, sequence)
        else:
            # ç›´æ¥å‘é€opusæ•°æ®åŒ…ï¼Œä¸æ·»åŠ å¤´éƒ¨
            await _send_audio_with_header(conn, audios, message_tag)

        # æ›´æ–°æµæ§çŠ¶æ€
        flow_control["packet_count"] += 1
        flow_control["sequence"] += 1
        flow_control["last_send_time"] = time.perf_counter()
    else:
        # æ–‡ä»¶å‹éŸ³é¢‘èµ°æ™®é€šæ’­æ”¾
        start_time = time.perf_counter()
        play_position = 0

        # æ‰§è¡Œé¢„ç¼“å†²
        pre_buffer_frames = min(3, len(audios))
        for i in range(pre_buffer_frames):
            if conn.conn_from_mqtt_gateway:
                # è®¡ç®—æ—¶é—´æˆ³å’Œåºåˆ—å·
                timestamp, sequence = calculate_timestamp_and_sequence(
                    conn, start_time, i, frame_duration
                )
                # è°ƒç”¨é€šç”¨å‡½æ•°å‘é€å¸¦å¤´éƒ¨çš„æ•°æ®åŒ…
                await _send_to_mqtt_gateway(conn, audios[i], timestamp, sequence)
            else:
                # ç›´æ¥å‘é€é¢„ç¼“å†²åŒ…ï¼Œä¸æ·»åŠ å¤´éƒ¨
                await _send_audio_with_header(conn, audios[i], message_tag)
        remaining_audios = audios[pre_buffer_frames:]

        # æ’­æ”¾å‰©ä½™éŸ³é¢‘å¸§
        for i, opus_packet in enumerate(remaining_audios):
            if conn.client_abort:
                break

            # é‡ç½®æ²¡æœ‰å£°éŸ³çš„çŠ¶æ€
            conn.last_activity_time = time.time() * 1000

            if send_delay > 0:
                # å›ºå®šå»¶è¿Ÿæ¨¡å¼
                await asyncio.sleep(send_delay)
            else:
                 # è®¡ç®—é¢„æœŸå‘é€æ—¶é—´
                expected_time = start_time + (play_position / 1000)
                current_time = time.perf_counter()
                delay = expected_time - current_time
                if delay > 0:
                    await asyncio.sleep(delay)

            if conn.conn_from_mqtt_gateway:
                # è®¡ç®—æ—¶é—´æˆ³å’Œåºåˆ—å·ï¼ˆä½¿ç”¨å½“å‰çš„æ•°æ®åŒ…ç´¢å¼•ç¡®ä¿è¿ç»­æ€§ï¼‰
                packet_index = pre_buffer_frames + i
                timestamp, sequence = calculate_timestamp_and_sequence(
                    conn, start_time, packet_index, frame_duration
                )
                # è°ƒç”¨é€šç”¨å‡½æ•°å‘é€å¸¦å¤´éƒ¨çš„æ•°æ®åŒ…
                await _send_to_mqtt_gateway(conn, opus_packet, timestamp, sequence)
            else:
                # ç›´æ¥å‘é€opusæ•°æ®åŒ…ï¼Œä¸æ·»åŠ å¤´éƒ¨
                await _send_audio_with_header(conn, opus_packet, message_tag)

            play_position += frame_duration


async def send_tts_message(conn, state, text=None, message_tag=MessageTag.NORMAL):
    """å‘é€ TTS çŠ¶æ€æ¶ˆæ¯
    
    Args:
        conn: Connection object
        state: TTS state (start, sentence_start, stop)
        text: Optional text content
        message_tag: Message tag for categorization
    """
    if text is None and state == "sentence_start":
        return
    
    message = {
        "type": "tts", 
        "state": state,
        "session_id": conn.session_id,
        "message_tag": message_tag.value,
    }
    if text is not None:
        text = textUtils.check_emoji(text)
        text = strip_emotion_tags(text)
        message["text"] = text

    # TTSæ’­æ”¾ç»“æŸ
    if state == "stop":
        # æ’­æ”¾æç¤ºéŸ³
        tts_notify = conn.config.get("enable_stop_tts_notify", False)
        if tts_notify:
            stop_tts_notify_voice = conn.config.get(
                "stop_tts_notify_voice", "config/assets/tts_notify.mp3"
            )
            audios = audio_to_data(stop_tts_notify_voice, is_opus=True)
            await sendAudio(conn, audios)
        # æ¸…é™¤æœåŠ¡ç«¯è®²è¯çŠ¶æ€
        conn.clearSpeakStatus()

    # å‘é€æ¶ˆæ¯åˆ°å®¢æˆ·ç«¯
    logger.bind(tag=TAG).info(f"å‘é€TTSæ¶ˆæ¯: {message}")
    await conn.websocket.send(json.dumps(message))


async def send_stt_message(conn, text):
    """å‘é€ STT çŠ¶æ€æ¶ˆæ¯"""
    end_prompt_str = conn.config.get("end_prompt", {}).get("prompt")
    if end_prompt_str and end_prompt_str == text:
        await send_tts_message(conn, "start")
        return

    # è§£æJSONæ ¼å¼ï¼Œæå–å®é™…çš„ç”¨æˆ·è¯´è¯å†…å®¹
    display_text = text
    try:
        # å°è¯•è§£æJSONæ ¼å¼
        if text.strip().startswith("{") and text.strip().endswith("}"):
            parsed_data = json.loads(text)
            if isinstance(parsed_data, dict) and "content" in parsed_data:
                # å¦‚æœæ˜¯åŒ…å«è¯´è¯äººä¿¡æ¯çš„JSONæ ¼å¼ï¼Œåªæ˜¾ç¤ºcontentéƒ¨åˆ†
                display_text = parsed_data["content"]
                # ä¿å­˜è¯´è¯äººä¿¡æ¯åˆ°connå¯¹è±¡
                if "speaker" in parsed_data:
                    conn.current_speaker = parsed_data["speaker"]
    except (json.JSONDecodeError, TypeError):
        # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡æœ¬
        display_text = text
    stt_text = textUtils.get_string_no_punctuation_or_emoji(display_text)
    await conn.websocket.send(
        json.dumps({"type": "stt", "text": stt_text, "session_id": conn.session_id})
    )
    conn.client_is_speaking = True
    await send_tts_message(conn, "start")
